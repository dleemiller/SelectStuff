{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45dbf20-cb76-45d7-9146-1d71b022b699",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11944382-00b8-4fee-9689-b8c9301269d9",
   "metadata": {},
   "source": [
    "## Setup models\n",
    "\n",
    "- **Teacher model**\n",
    "    - should be the model you intend to user, or a stronger model.\n",
    "    - This model can bootstrap examples and instructions to \"train\" the weaker model.\n",
    "\n",
    "**Student model**\n",
    "- the model you intend to use in the program.\n",
    "\n",
    "\n",
    "Note: Using the `cache=True` setting you can restart the program to resume where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e56b30b-9f4c-4c71-bcec-1e7c2f3a1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import dspy\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "\n",
    "# set your api key (if needed)\n",
    "load_dotenv(\"../../.env\")\n",
    "APIKEY = os.getenv(\"APIKEY\")\n",
    "\n",
    "# set your model (litellm model strings)\n",
    "student_model = \"openrouter/meta-llama/llama-3.2-3b-instruct\"\n",
    "# student_model = \"openrouter/meta-llama/llama-3-8b-instruct\"\n",
    "teacher_model = \"openrouter/deepseek/deepseek-chat\"\n",
    "lm = dspy.LM(student_model, api_key=APIKEY, cache=True)\n",
    "teacher_lm = dspy.LM(teacher_model, api_key=APIKEY, cache=True)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc69be5-6eaa-424c-aa58-c0ecf0e0b278",
   "metadata": {},
   "source": [
    "## Load the Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb62a0e-86d7-487a-aca4-f66b8c7ddd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples: 100\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "data = []\n",
    "for file in glob.glob(\"training_data/accepted/*.json\"):\n",
    "    with open(file, \"r\") as fh:\n",
    "        tmp = json.load(fh)\n",
    "\n",
    "        # convert to date\n",
    "        tmp[\"publication_date\"] = datetime.strptime(tmp[\"publication_date\"], \"%Y-%m-%d\").date() if tmp[\"publication_date\"] else None\n",
    "\n",
    "        # remove reasoning from example\n",
    "        if \"reasoning\" in tmp:\n",
    "            del tmp[\"reasoning\"]\n",
    "\n",
    "        e = dspy.Example(tmp).with_inputs(\"article_text\")\n",
    "        data.append(e)\n",
    "\n",
    "print(f\"# Examples: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ca100-e36a-4866-9914-dcba6e1aa689",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "**WordLlamaScorer** handles some automatic scoring using `wordllama`.\n",
    "I wrote some basic functions to autmatically evaluate the most common types:\n",
    "- `str` using jaccard similarity for short strings and wordllama similarity for longer strings\n",
    "- distance functions for `int`, `float` and `date` types\n",
    "- exact matching for `Literal`\n",
    "\n",
    "Of course, it's always better to write to your own specific use cases, but this may be sufficient for many programs.\n",
    "\n",
    "MIPROv2 has worked well for me. I start with `medium` settings, which will run for quite a while. I would generally use the `heavy` setting and let it run overnight with sufficient training data for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641e929-84ba-401f-91fe-24c6d0ba44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scorer\")\n",
    "from scorer import WordLlamaScorer\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "from news_app import NewsAppSignature\n",
    "\n",
    "training\n",
    "scorer = WordLlamaScorer.from_signature(NewsAppSignature, skip_fields=[\"article_text\", \"reasoning\"])\n",
    "\n",
    "\n",
    "teleprompter = MIPROv2(\n",
    "    metric=scorer,\n",
    "    auto=\"medium\",\n",
    "    teacher_settings=dict(lm=teacher_lm),\n",
    "    num_threads=2\n",
    ")\n",
    "\n",
    "catalog = dspy.ChainOfThought(NewsAppSignature)\n",
    "optimized_program = teleprompter.compile(\n",
    "    student=catalog.deepcopy(),\n",
    "    teacher=catalog.deepcopy(),\n",
    "    trainset=data,\n",
    "    max_bootstrapped_demos=2,\n",
    "    max_labeled_demos=2,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702a2c5-a43f-4f78-9d72-613d3e8b937d",
   "metadata": {},
   "source": [
    "## Save Program\n",
    "\n",
    "Save the training recipe. Use it in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3d784c-c80c-4871-afcf-ac6637c264b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "for demo in optimized_program.demos:\n",
    "    if 'publication_date' in demo and isinstance(demo['publication_date'], date):\n",
    "        demo['publication_date'] = demo['publication_date'].isoformat()\n",
    "\n",
    "# Save the state to a JSON file\n",
    "optimized_program.save(\"miprov2_llama32_3b.json\", save_program=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
